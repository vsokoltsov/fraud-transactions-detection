{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3c4485",
   "metadata": {},
   "source": [
    "# 4. Feature engineering - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from notebooks.utils import save_features, save_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086bfe7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "upstream = {\n",
    "    'split_data': {\n",
    "        'train': 'data/interim/x_train_split.parquet.gzip',\n",
    "        'val': 'data/interim/x_val_split.parquet.gzip',\n",
    "        'test': 'data/interim/x_test_split.parquet.gzip'\n",
    "    }\n",
    "}\n",
    "product = None\n",
    "ROOT = Path(os.path.abspath(\"\")).resolve().parents[0]\n",
    "DATA = os.path.join(ROOT, \"data\")\n",
    "INTERIM_DATA = os.path.join(DATA, \"interim\")\n",
    "VERSION = \"v2\"\n",
    "eps = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bcc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(os.path.join(INTERIM_DATA, \"x_train_split.parquet.gzip\"))\n",
    "X_val = pd.read_parquet(os.path.join(INTERIM_DATA, \"x_val_split.parquet.gzip\"))\n",
    "X_test = pd.read_parquet(os.path.join(INTERIM_DATA, \"x_test_split.parquet.gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a907f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAMES = [X_train, X_val, X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6b99b",
   "metadata": {},
   "source": [
    "## Features to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef3a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(DATAFRAMES):\n",
    "    df[\"tx_amount_log_mean\"] = df.groupby(\"customer_id\")[\"tx_amount_log\"].transform(\n",
    "        \"mean\"\n",
    "    )\n",
    "    df[\"tx_amount_log_std\"] = df.groupby(\"customer_id\")[\"tx_amount_log\"].transform(\n",
    "        \"std\"\n",
    "    )\n",
    "    df[\"tx_amount_log_deviates\"] = (\n",
    "        (df[\"tx_amount_log\"] < (df[\"tx_amount_log_mean\"] - df[\"tx_amount_log_std\"]))\n",
    "        | (df[\"tx_amount_log\"] > (df[\"tx_amount_log_mean\"] + df[\"tx_amount_log_std\"]))\n",
    "    ).astype(int)\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ea6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(DATAFRAMES):\n",
    "    df[\"secs_since_prev_tx\"] = (\n",
    "        df.groupby(\"customer_id\")[\"tx_datetime\"].diff().dt.total_seconds().fillna(-1)\n",
    "    )\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811be602",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(DATAFRAMES):\n",
    "    df[\"burst_id\"] = df.groupby(\"customer_id\")[\"secs_since_prev_tx\"].transform(\n",
    "        lambda x: (x > 3600).cumsum()\n",
    "    )\n",
    "    df[\"n_tx_in_burst\"] = df.groupby([\"customer_id\", \"burst_id\"])[\n",
    "        \"tx_amount_log\"\n",
    "    ].transform(\"count\")\n",
    "    df[\"burst_mean\"] = (\n",
    "        df.groupby(\"customer_id\")[\"n_tx_in_burst\"].transform(\"mean\").fillna(0)\n",
    "    )\n",
    "    df[\"burst_std\"] = (\n",
    "        df.groupby(\"customer_id\")[\"n_tx_in_burst\"].transform(\"std\").fillna(0)\n",
    "    )\n",
    "    df[\"n_trx_per_burst_deviates\"] = (\n",
    "        (df[\"n_tx_in_burst\"] < (df[\"burst_mean\"] - df[\"burst_std\"]))\n",
    "        | (df[\"n_tx_in_burst\"] > (df[\"burst_mean\"] + df[\"burst_std\"]))\n",
    "    ).astype(int)\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/2252554451.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['zscore'] = df.groupby('customer_id').apply(lambda x: (x['tx_amount_log'] - x['tx_amount_log_mean']) / x['tx_amount_log_std']).to_numpy()\n",
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/2252554451.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['zscore'] = df.groupby('customer_id').apply(lambda x: (x['tx_amount_log'] - x['tx_amount_log_mean']) / x['tx_amount_log_std']).to_numpy()\n",
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/2252554451.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['zscore'] = df.groupby('customer_id').apply(lambda x: (x['tx_amount_log'] - x['tx_amount_log_mean']) / x['tx_amount_log_std']).to_numpy()\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-9\n",
    "\n",
    "for i, df in enumerate(DATAFRAMES):\n",
    "    df[\"zscore\"] = (\n",
    "        df.groupby(\"customer_id\")\n",
    "        .apply(\n",
    "            lambda x: (x[\"tx_amount_log\"] - x[\"tx_amount_log_mean\"])\n",
    "            / x[\"tx_amount_log_std\"]\n",
    "        )\n",
    "        .to_numpy()\n",
    "    )\n",
    "    df[\"is_zscore_outlier\"] = (df[\"zscore\"] > 3).astype(int)\n",
    "    q1 = df.groupby(\"customer_id\")[\"tx_amount_log\"].transform(\n",
    "        lambda s: s.quantile(0.25)\n",
    "    )\n",
    "    q3 = df.groupby(\"customer_id\")[\"tx_amount_log\"].transform(\n",
    "        lambda s: s.quantile(0.75)\n",
    "    )\n",
    "    med = df.groupby(\"customer_id\")[\"tx_amount_log\"].transform(\"median\")\n",
    "    iqr = (q3 - q1).replace(0, np.nan).fillna(eps)\n",
    "    df[\"is_iqr_outlier\"] = (\n",
    "        ~df[\"tx_amount_log\"].between(q1 - 0.5 * iqr, q3 + 0.5 * iqr)\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"tx_amount_log_scaled\"] = (df[\"tx_amount_log\"] - med) / iqr\n",
    "    df[\"is_rs_anomaly\"] = (df[\"tx_amount_log_scaled\"].abs() > 1.5).astype(int)\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88953a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/1020596804.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['hour_zscore'] = df.groupby('customer_id').apply(lambda x: (x['hour'] - x['hour'].mean()) / x['hour'].std()).to_numpy()\n",
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/1020596804.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['hour_zscore'] = df.groupby('customer_id').apply(lambda x: (x['hour'] - x['hour'].mean()) / x['hour'].std()).to_numpy()\n",
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/1020596804.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['hour_zscore'] = df.groupby('customer_id').apply(lambda x: (x['hour'] - x['hour'].mean()) / x['hour'].std()).to_numpy()\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(DATAFRAMES):\n",
    "    df[\"hour_zscore\"] = (\n",
    "        df.groupby(\"customer_id\")\n",
    "        .apply(lambda x: (x[\"hour\"] - x[\"hour\"].mean()) / x[\"hour\"].std())\n",
    "        .to_numpy()\n",
    "    )\n",
    "    df[\"hour_zscore_deviates\"] = (df[\"hour_zscore\"].abs() > 2).astype(int)\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9b2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 20\n",
    "min_periods = 5\n",
    "\n",
    "for i, df in enumerate(DATAFRAMES):\n",
    "    df = df.sort_values([\"customer_id\", \"tx_datetime\"]).copy()\n",
    "    g = df.groupby(\"customer_id\", sort=False)\n",
    "    r5 = g[\"tx_amount_log\"].rolling(window=window, min_periods=min_periods)\n",
    "    r1 = g[\"tx_amount_log\"].rolling(window=window, min_periods=1)\n",
    "\n",
    "    # базовые rolling-метрики (могут быть NaN на первых minp-1 строках)\n",
    "    med5 = r5.median().reset_index(level=0, drop=True)\n",
    "    q1_5 = r5.quantile(0.25).reset_index(level=0, drop=True)\n",
    "    q3_5 = r5.quantile(0.75).reset_index(level=0, drop=True)\n",
    "\n",
    "    # фолбэк-метрики (без NaN из-за min_periods)\n",
    "    med1 = r1.median().reset_index(level=0, drop=True)\n",
    "    q1_1 = r1.quantile(0.25).reset_index(level=0, drop=True)\n",
    "    q3_1 = r1.quantile(0.75).reset_index(level=0, drop=True)\n",
    "\n",
    "    # подставляем фолбэк туда, где базовые NaN\n",
    "    df[\"rolling_median\"] = med5.fillna(med1)\n",
    "    df[\"q1\"] = q1_5.fillna(q1_1)\n",
    "    df[\"q3\"] = q3_5.fillna(q3_1)\n",
    "\n",
    "    df[\"iqr\"] = df[\"q3\"] - df[\"q1\"]\n",
    "\n",
    "    df[\"amount_robust_rolling20\"] = (df[\"tx_amount_log\"] - df[\"rolling_median\"]) / (\n",
    "        df[\"iqr\"] + eps\n",
    "    )\n",
    "\n",
    "    df[\"amount_robust_rolling20\"] = df[\"amount_robust_rolling20\"].fillna(0)\n",
    "    df[\"is_amount_robust_rolling_outlier\"] = (df[\"amount_robust_rolling20\"] > 3).astype(\n",
    "        int\n",
    "    )\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8e9a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/3619821532.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['day_of_week_zscore'] =  df.groupby('customer_id').apply(lambda x: (x['day_of_week'] - x['day_of_week_mean']) / x['day_of_week_std']).to_numpy()\n",
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/3619821532.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['day_of_week_zscore'] =  df.groupby('customer_id').apply(lambda x: (x['day_of_week'] - x['day_of_week_mean']) / x['day_of_week_std']).to_numpy()\n",
      "/var/folders/v0/8r5h4ym13fb_mzmqc1hfkt580000gn/T/ipykernel_36608/3619821532.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['day_of_week_zscore'] =  df.groupby('customer_id').apply(lambda x: (x['day_of_week'] - x['day_of_week_mean']) / x['day_of_week_std']).to_numpy()\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(DATAFRAMES):\n",
    "    mean_ = df.groupby(\"customer_id\")[\"day_of_week\"].transform(\"mean\")\n",
    "    std_ = df.groupby(\"customer_id\")[\"day_of_week\"].transform(\"std\")\n",
    "    df[\"day_of_week_mean\"] = mean_.fillna(0)\n",
    "    df[\"day_of_week_std\"] = std_.fillna(0)\n",
    "    df[\"is_day_of_week_mean_outlier\"] = (\n",
    "        (df[\"day_of_week\"] < (df[\"day_of_week_mean\"] - df[\"day_of_week_std\"]))\n",
    "        | (df[\"day_of_week\"] > (df[\"day_of_week_mean\"] + df[\"day_of_week_std\"]))\n",
    "    ).astype(int)\n",
    "    df[\"day_of_week_zscore\"] = (\n",
    "        df.groupby(\"customer_id\")\n",
    "        .apply(\n",
    "            lambda x: (x[\"day_of_week\"] - x[\"day_of_week_mean\"]) / x[\"day_of_week_std\"]\n",
    "        )\n",
    "        .to_numpy()\n",
    "    )\n",
    "    df[\"is_day_of_week_zscore_outlier\"] = (df[\"day_of_week_zscore\"].abs() > 2).astype(\n",
    "        int\n",
    "    )\n",
    "    DATAFRAMES[i] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee958265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(DATAFRAMES):\n",
    "    dfc = df.sort_values([\"customer_id\", \"tx_datetime\"]).reset_index(drop=True).copy()\n",
    "    dfc[\"n_tx_in_prev_24h\"] = 0\n",
    "    one_day = np.timedelta64(1, \"D\")\n",
    "\n",
    "    for cid, grp in dfc.groupby(\"customer_id\"):\n",
    "        t = grp[\"tx_datetime\"].to_numpy(\"datetime64[ns]\")\n",
    "        left = t - one_day\n",
    "        j = np.searchsorted(t, left, side=\"left\")\n",
    "        cnt = np.arange(len(t)) - j\n",
    "        dfc.loc[grp.index, \"n_tx_in_prev_24h\"] = cnt.astype(int)\n",
    "\n",
    "    g = dfc.groupby(\"customer_id\")\n",
    "    dfc[\"q90_prev\"] = g[\"n_tx_in_prev_24h\"].transform(\n",
    "        lambda s: s.shift(1).expanding().quantile(0.90).fillna(0)\n",
    "    )\n",
    "    dfc[\"is_24h_burst\"] = (\n",
    "        (dfc[\"n_tx_in_prev_24h\"] >= dfc[\"q90_prev\"]).fillna(False).astype(int)\n",
    "    )\n",
    "    dfc[\"is_24h_burst_fixed\"] = (dfc[\"n_tx_in_prev_24h\"] >= 3).astype(int)\n",
    "    dfc[\"day\"] = dfc[\"tx_datetime\"].dt.date\n",
    "    dg = dfc.groupby([\"customer_id\", \"day\"])[\"tx_amount_log\"]\n",
    "\n",
    "    day_median = dg.transform(\"median\")\n",
    "    day_mad = dg.transform(lambda s: (s - s.median()).abs().median())\n",
    "    dfc[\"z_in_day_robust\"] = (dfc[\"tx_amount_log\"] - day_median) / (\n",
    "        1.4826 * day_mad + eps\n",
    "    )\n",
    "\n",
    "    dfc[\"is_anomalous_in_day\"] = (dfc[\"z_in_day_robust\"].abs() > 2.5).astype(int)\n",
    "    dfc[\"fraud_burst_candidate\"] = (\n",
    "        (dfc[\"is_24h_burst\"] == 1) & (dfc[\"z_in_day_robust\"] > 1.0)\n",
    "    ).astype(int)\n",
    "    DATAFRAMES[i] = dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fe897",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96224bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"tx_amount\",\n",
    "    \"sector_id\",\n",
    "    \"tx_amount_log\",\n",
    "    \"hour\",\n",
    "    \"month\",\n",
    "    \"is_month_start\",\n",
    "    \"is_month_end\",\n",
    "    \"is_weekend\",\n",
    "    \"tx_amount_log_mean\",\n",
    "    \"tx_amount_log_std\",\n",
    "    \"tx_amount_log_deviates\",\n",
    "    \"secs_since_prev_tx\",\n",
    "    \"burst_id\",\n",
    "    \"n_tx_in_burst\",\n",
    "    \"burst_mean\",\n",
    "    \"burst_std\",\n",
    "    \"n_trx_per_burst_deviates\",\n",
    "    \"hour_zscore\",\n",
    "    \"hour_zscore_deviates\",\n",
    "    \"rolling_median\",\n",
    "    \"q1\",\n",
    "    \"q3\",\n",
    "    \"iqr\",\n",
    "    \"amount_robust_rolling20\",\n",
    "    \"is_amount_robust_rolling_outlier\",\n",
    "    \"day_of_week_mean\",\n",
    "    \"day_of_week_std\",\n",
    "    \"is_day_of_week_mean_outlier\",\n",
    "    \"day_of_week_zscore\",\n",
    "    \"is_day_of_week_zscore_outlier\",\n",
    "    \"n_tx_in_prev_24h\",\n",
    "    \"q90_prev\",\n",
    "    \"is_24h_burst\",\n",
    "    \"is_24h_burst_fixed\",\n",
    "    \"day_of_week\",\n",
    "    \"z_in_day_robust\",\n",
    "    \"is_anomalous_in_day\",\n",
    "    \"fraud_burst_candidate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ede7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1625b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                         0\n",
       "tx_datetime                         0\n",
       "tx_amount                           0\n",
       "sector_id                           0\n",
       "tx_fraud                            0\n",
       "tx_amount_log                       0\n",
       "ones                                0\n",
       "day_of_week                         0\n",
       "hour                                0\n",
       "month                               0\n",
       "is_month_start                      0\n",
       "is_month_end                        0\n",
       "is_weekend                          0\n",
       "tx_amount_log_mean                  0\n",
       "tx_amount_log_std                   0\n",
       "tx_amount_log_deviates              0\n",
       "secs_since_prev_tx                  0\n",
       "burst_id                            0\n",
       "n_tx_in_burst                       0\n",
       "burst_mean                          0\n",
       "burst_std                           0\n",
       "n_trx_per_burst_deviates            0\n",
       "zscore                              0\n",
       "is_zscore_outlier                   0\n",
       "is_iqr_outlier                      0\n",
       "tx_amount_log_scaled                0\n",
       "is_rs_anomaly                       0\n",
       "hour_zscore                         0\n",
       "hour_zscore_deviates                0\n",
       "rolling_median                      0\n",
       "q1                                  0\n",
       "q3                                  0\n",
       "iqr                                 0\n",
       "amount_robust_rolling20             0\n",
       "is_amount_robust_rolling_outlier    0\n",
       "day_of_week_mean                    0\n",
       "day_of_week_std                     0\n",
       "is_day_of_week_mean_outlier         0\n",
       "day_of_week_zscore                  0\n",
       "is_day_of_week_zscore_outlier       0\n",
       "n_tx_in_prev_24h                    0\n",
       "q90_prev                            0\n",
       "is_24h_burst                        0\n",
       "is_24h_burst_fixed                  0\n",
       "day                                 0\n",
       "z_in_day_robust                     0\n",
       "is_anomalous_in_day                 0\n",
       "fraud_burst_candidate               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d419cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_features(os.path.join(INTERIM_DATA, f\"features_{VERSION}.yaml\"), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93801629",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22e2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dataframes(\n",
    "    {\n",
    "        os.path.join(INTERIM_DATA, f\"x_train_features_{VERSION}.parquet.gzip\"): X_train,\n",
    "        os.path.join(INTERIM_DATA, f\"x_val_features_{VERSION}.parquet.gzip\"): X_val,\n",
    "        os.path.join(INTERIM_DATA, f\"x_test_features_{VERSION}.parquet.gzip\"): X_test,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Tech Assignment",
   "name": "ml-tech-assignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
